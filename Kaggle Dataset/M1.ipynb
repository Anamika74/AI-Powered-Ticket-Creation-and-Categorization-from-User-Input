{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7cc990",
   "metadata": {},
   "source": [
    "‚óè\tModule 1: Data Collection and Preprocessing\n",
    "\n",
    "‚óã\tCollect a diverse dataset of past user issues and their corresponding structured ticket data.\n",
    "\n",
    "‚óã\tClean and preprocess the text data to handle inconsistencies, spelling errors, and irrelevant information.\n",
    "\n",
    "‚óã\tAnnotate the dataset with labels for ticket categories, priorities, and named entities.\n",
    "\n",
    "\tMilestone 1 : Data Preparation & Annotation\n",
    "‚óã\tObjective: Collect and prepare a clean, annotated dataset.\n",
    "\n",
    "‚óã\tTasks: Collect a diverse set of historical ticket data;\n",
    "clean and normalize text; \n",
    "manually annotate a portion of the data for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219f7788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2052f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connection with icon icon dear please setup ic...</td>\n",
       "      <td>Hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work experience user work experience user hi w...</td>\n",
       "      <td>Access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>requesting for meeting requesting meeting hi p...</td>\n",
       "      <td>Hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reset passwords for external accounts re expir...</td>\n",
       "      <td>Access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mail verification warning hi has got attached ...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document    Topic_group\n",
       "0  connection with icon icon dear please setup ic...       Hardware\n",
       "1  work experience user work experience user hi w...         Access\n",
       "2  requesting for meeting requesting meeting hi p...       Hardware\n",
       "3  reset passwords for external accounts re expir...         Access\n",
       "4  mail verification warning hi has got attached ...  Miscellaneous"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- STEP 1: LOAD DATA ---\n",
    "# We use the raw IT tickets CSV containing ~47k records\n",
    "df = pd.read_csv(r'D:\\AI-Powered Ticket Creation & Categorization\\Kaggle Dataset\\all_tickets_processed_improved_v3.csv')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fc7e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47837, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "162b059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47837 entries, 0 to 47836\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Document     47837 non-null  object\n",
      " 1   Topic_group  47837 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 747.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0b2a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47837</td>\n",
       "      <td>47837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>47837</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>connection with icon icon dear please setup ic...</td>\n",
       "      <td>Hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>13617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Document Topic_group\n",
       "count                                               47837       47837\n",
       "unique                                              47837           8\n",
       "top     connection with icon icon dear please setup ic...    Hardware\n",
       "freq                                                    1       13617"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9552b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 2: LIGHT CLEANING ---\n",
    "# BERT needs sentence structure, so we only remove \"noise\" like URLs/Emails\n",
    "def bert_cleaning(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<[^>]+>', '', text)     \n",
    "    text = re.sub(r'\\S+@\\S+', '', text)      \n",
    "    text = re.sub(r'http\\S+', '', text)      \n",
    "    text = re.sub(r'[^a-z0-9!?. ]', '', text) \n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "df['clean_text'] = df['Document'].apply(bert_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e267c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3: LABEL ENCODING ---\n",
    "# Convert 'Hardware', 'Access', etc., into numbers 0-7\n",
    "df['label'] = df['Topic_group'].astype('category').cat.codes\n",
    "num_labels = df['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f7de190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milestone 1 running on: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 4: CLASS WEIGHTS (THE ACCURACY BOOSTER) ---\n",
    "y_labels = df['label'].values\n",
    "weights = compute_class_weight(class_weight='balanced', \n",
    "                               classes=np.unique(y_labels), \n",
    "                               y=y_labels)\n",
    "\n",
    "# üöÄ THE FIX: Use CPU if GPU is not available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "\n",
    "print(f\"Milestone 1 running on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "925570e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 5: SPLIT DATA ---\n",
    "train_df, test_df = train_test_split(df, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e7f9fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic_group</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connection with icon icon dear please setup ic...</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>connection with icon icon dear please setup ic...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work experience user work experience user hi w...</td>\n",
       "      <td>Access</td>\n",
       "      <td>work experience user work experience user hi w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>requesting for meeting requesting meeting hi p...</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>requesting for meeting requesting meeting hi p...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reset passwords for external accounts re expir...</td>\n",
       "      <td>Access</td>\n",
       "      <td>reset passwords for external accounts re expir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mail verification warning hi has got attached ...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>mail verification warning hi has got attached ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document    Topic_group  \\\n",
       "0  connection with icon icon dear please setup ic...       Hardware   \n",
       "1  work experience user work experience user hi w...         Access   \n",
       "2  requesting for meeting requesting meeting hi p...       Hardware   \n",
       "3  reset passwords for external accounts re expir...         Access   \n",
       "4  mail verification warning hi has got attached ...  Miscellaneous   \n",
       "\n",
       "                                          clean_text  label  \n",
       "0  connection with icon icon dear please setup ic...      3  \n",
       "1  work experience user work experience user hi w...      0  \n",
       "2  requesting for meeting requesting meeting hi p...      3  \n",
       "3  reset passwords for external accounts re expir...      0  \n",
       "4  mail verification warning hi has got attached ...      5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff7edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Traditional steps like stemming and stop-word \n",
      "removal were intentionally skipped because BERT is a contextual model.\n",
      "Keeping the full sentence structure allows the model to \n",
      "leverage its pre-trained linguistic knowledge more \n",
      "effectively than if we had reduced the text to just keywords.\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(''' \n",
    "Traditional steps like stemming and stop-word \n",
    "removal were intentionally skipped because BERT is a contextual model.\n",
    "Keeping the full sentence structure allows the model to \n",
    "leverage its pre-trained linguistic knowledge more \n",
    "effectively than if we had reduced the text to just keywords.\n",
    "      ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11ecd1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing Stop Words\n",
      "\n",
      "Reason: BERT uses Attention Mechanisms to process the\n",
      "relationship between all words. Removing stop words destroys \n",
      "grammatical context, hindering BERT's ability to \n",
      "grasp the user's true intent.\n",
      "\n",
      "Stemming or Lemmatization\n",
      "\n",
      "Reason: BERT employs WordPiece Tokenization, which \n",
      "natively breaks words into sub-units (e.g., \"flicker\" and \"##ing\"). \n",
      "Manual reduction is unnecessary and loses the linguistic \n",
      "nuance of the original input.\n",
      "\n",
      "Heavy Punctuation Removal\n",
      "\n",
      "Reason: Basic marks like ! and ? were preserved as they are\n",
      "critical for determining sentiment and urgency \n",
      "(e.g., identifying a \"critical\" vs. \"general\" query).\n",
      "\n",
      "SMOTE (Synthetic Over-sampling)\n",
      "\n",
      "Reason: Rather than generating \"synthetic\" data, Class Weights \n",
      "were applied to the loss function. This is more \n",
      "effective \n",
      "for high-dimensional text and prevents overfitting on artificial examples.      \n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "Removing Stop Words\n",
    "\n",
    "Reason: BERT uses Attention Mechanisms to process the\n",
    "relationship between all words. Removing stop words destroys \n",
    "grammatical context, hindering BERT's ability to \n",
    "grasp the user's true intent.\n",
    "\n",
    "Stemming or Lemmatization\n",
    "\n",
    "Reason: BERT employs WordPiece Tokenization, which \n",
    "natively breaks words into sub-units (e.g., \"flicker\" and \"##ing\"). \n",
    "Manual reduction is unnecessary and loses the linguistic \n",
    "nuance of the original input.\n",
    "\n",
    "Heavy Punctuation Removal\n",
    "\n",
    "Reason: Basic marks like ! and ? were preserved as they are\n",
    "critical for determining sentiment and urgency \n",
    "(e.g., identifying a \"critical\" vs. \"general\" query).\n",
    "\n",
    "SMOTE (Synthetic Over-sampling)\n",
    "\n",
    "Reason: Rather than generating \"synthetic\" data, Class Weights \n",
    "were applied to the loss function. This is more \n",
    "effective \n",
    "for high-dimensional text and prevents overfitting on artificial examples.      \n",
    "      ''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
