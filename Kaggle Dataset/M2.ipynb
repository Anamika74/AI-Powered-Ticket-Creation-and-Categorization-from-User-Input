{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e994f59",
   "metadata": {},
   "source": [
    "\tMilestone 2 : Core Model Development\n",
    "○\tObjective: Train and validate the NLP and NER models.\n",
    "○\tTasks: Select appropriate models (e.g., scikit-learn classifiers, \n",
    "           SpaCy  for NER); \n",
    "           train the models on the annotated dataset; evaluate initial model accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae85892",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (AutoTokenizer, AutoModelForSequenceClassification, \n\u001b[0;32m      4\u001b[0m                           TrainingArguments, Trainer, DataCollatorWithPadding)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 6: TOKENIZATION ---\n",
    "# Convert text into the specific ID format BERT understands\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"clean_text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[['clean_text', 'label']]).map(tokenize_fn, batched=True)\n",
    "test_ds = Dataset.from_pandas(test_df[['clean_text', 'label']]).map(tokenize_fn, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4692f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 7: CUSTOM WEIGHTED TRAINER ---\n",
    "# This forces the model to learn the 3.7% minority class by increasing its error penalty\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # Use the class_weights we calculated in Milestone 1\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# --- STEP 7.5: DEFINE THE EVALUATION METRIC ---\n",
    "# This function tells the Trainer how to calculate accuracy\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,   # The Trainer will automatically prefix this with 'eval_'\n",
    "        'f1': f1\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7de36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 8: UPDATED TRAINING ARGUMENTS ---\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"weighted_bert_final\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    # IMPORTANT: The key must be 'eval_accuracy' because Trainer prefixes 'eval_' to metrics\n",
    "    metric_for_best_model=\"eval_accuracy\", \n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b52d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 9: UPDATED TRAINER ---\n",
    "trainer = WeightedTrainer(\n",
    "    model=model, \n",
    "    args=args, \n",
    "    train_dataset=train_ds, \n",
    "    eval_dataset=test_ds, \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics  # DO NOT FORGET THIS LINE\n",
    ")\n",
    "\n",
    "print(\"Starting Training with Metrics...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# This will save the BEST version (Epoch 3) because of our Trainer settings\n",
    "model_path = \"champion_weighted_bert\"\n",
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "# Zip it for download\n",
    "shutil.make_archive('it_ticket_final_bert', 'zip', model_path)\n",
    "\n",
    "print(\"SUCCESS: Your 86.9% Accuracy model is zipped and ready in the Output tab!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c89706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "# 1. Vectorize text using TF-IDF\n",
    "# We use max_features=5000 to keep it efficient on Kaggle\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "\n",
    "print(\"Vectorizing data for SVM...\")\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['clean_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['clean_text'])\n",
    "\n",
    "# 2. Train the SVM\n",
    "# probability=True is ESSENTIAL for the Soft Voting ensemble!\n",
    "print(\"Training SVM Specialist (probability=True)...\")\n",
    "svm_model = SVC(kernel='linear', probability=True, class_weight='balanced')\n",
    "svm_model.fit(X_train_tfidf, train_df['label'])\n",
    "\n",
    "# 3. Quick Accuracy Check for SVM\n",
    "svm_acc = svm_model.score(X_test_tfidf, test_df['label'])\n",
    "print(f\"✅ SVM Specialist Accuracy: {svm_acc:.4f}\")\n",
    "\n",
    "# 4. Save for the Ensemble & Milestone 3\n",
    "joblib.dump(svm_model, 'svm_model.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87cd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def ensemble_predict(text):\n",
    "    # --- PART A: BERT CONFIDENCE ---\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        bert_logits = model(**inputs).logits\n",
    "    bert_probs = torch.softmax(bert_logits, dim=1).cpu().numpy()[0]\n",
    "    \n",
    "    # --- PART B: SVM CONFIDENCE ---\n",
    "    tfidf_feat = tfidf_vectorizer.transform([text])\n",
    "    svm_probs = svm_model.predict_proba(tfidf_feat)[0]\n",
    "    \n",
    "    # --- PART C: SOFT VOTING (WEIGHTED) ---\n",
    "    # Give BERT (the deep learner) 60% and SVM (the keyword expert) 40%\n",
    "    final_probs = (0.6 * bert_probs) + (0.4 * svm_probs)\n",
    "    return np.argmax(final_probs)\n",
    "\n",
    "# Test on a new ticket\n",
    "sample = \"I need access to the internal storage folder for the new project.\"\n",
    "print(f\"Ensemble Result: {ensemble_predict(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# 1. Load a lightweight NER model (spaCy)\n",
    "# Run !python -m spacy download en_core_web_sm in a cell first\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_entities_and_priority(text, category):\n",
    "    # --- NER SECTION ---\n",
    "    doc = nlp(text)\n",
    "    entities = {\n",
    "        \"usernames\": [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"],\n",
    "        \"machine_names\": re.findall(r'[A-Z0-9]+(?:-[A-Z0-9]+)+', text), # Finds strings like LAPTOP-X1\n",
    "        \"error_codes\": re.findall(r'0x[0-9a-fA-F]+|\\b\\d{3,4}\\b', text)    # Finds 0x8004 or 404\n",
    "    }\n",
    "\n",
    "    # --- PRIORITY & SENTIMENT SECTION ---\n",
    "    # Keywords that indicate urgency\n",
    "    urgent_keywords = ['emergency', 'urgent', 'immediately', 'stopped', 'broken', 'dead', 'critical']\n",
    "    is_urgent = any(word in text.lower() for word in urgent_keywords)\n",
    "    \n",
    "    # Priority Logic based on User Intent (Context)\n",
    "    if is_urgent or category in ['Access', 'Security']:\n",
    "        priority = \"High\"\n",
    "    elif category in ['Hardware', 'Storage']:\n",
    "        priority = \"Medium\"\n",
    "    else:\n",
    "        priority = \"Low\"\n",
    "        \n",
    "    return entities, priority\n",
    "\n",
    "# --- TEST IT OUT ---\n",
    "sample_text = \"Urgent: User Adison is reporting Error 0x8004 on LAPTOP-P12. Screen is dead.\"\n",
    "sample_category = \"Hardware\" # This would come from your BERT model\n",
    "\n",
    "entities, priority = extract_entities_and_priority(sample_text, sample_category)\n",
    "\n",
    "print(f\"Entities Found: {entities}\")\n",
    "print(f\"Assigned Priority: {priority}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431add58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import joblib\n",
    "\n",
    "# 1. Save the SVM files\n",
    "joblib.dump(svm_model, 'svm_model.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# 2. Save the BERT model (Best version from Epoch 3)\n",
    "trainer.save_model(\"final_bert_model\")\n",
    "tokenizer.save_pretrained(\"final_bert_model\")\n",
    "\n",
    "# 3. Zip everything into one download\n",
    "# This creates 'milestone_2_final.zip'\n",
    "shutil.make_archive('milestone_2_final', 'zip', './', './')\n",
    "\n",
    "print(\"✅ ALL MODELS SAVED! Download 'milestone_2_final.zip' from the Output tab.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17202cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Use your actual dataframe counts\n",
    "class_counts = df['Topic_group'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('pastel'))\n",
    "plt.title('Distribution of IT Ticket Categories')\n",
    "plt.axis('equal') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8721e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for your test set\n",
    "# (You'll need to run your ensemble_predict function on test_df['clean_text'])\n",
    "y_pred = [ensemble_predict(txt) for txt in test_df['clean_text'].iloc[:100]] # Test first 100 for speed\n",
    "y_true = test_df['label'].iloc[:100]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel('Predicted Category')\n",
    "plt.ylabel('Actual Category')\n",
    "plt.title('Final Ensemble Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
